import streamlit as st
from langchain.text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableMap
from operator import itemgetter
import pyttsx3
from PyPDF2 import PdfReader
import os
from dotenv import load_dotenv


# Load API keys
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Token-Protected access
SECRET_TOKEN = "yalistudy2025"
token = st.query_params.get("token", "").strip()

if token != SECRET_TOKEN:
    st.error("‚ùå Access Denied. You need a valid link to access this app.")
    st.stop()

# Welcome message
st.markdown("""
### üëã Hello Yalitza  
I am an AI Agent created by **Marcos Hodge** to assist you with your studies.
""")

# Load and index book on startup
@st.cache_resource
def load_book_qa(book_path):
    reader = PdfReader(book_path)
    text = "".join([p.extract_text() or "" for p in reader.pages])
    chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_text(text)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_texts(chunks, embedding=embeddings)
    retriever = vectorstore.as_retriever()

    prompt = PromptTemplate.from_template(
        "Use the context below to answer the question:\n\n{context}\n\nQuestion: {question}"
    )

    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

    chain = RunnableMap({
        "context": itemgetter("question") | retriever,
        "question": itemgetter("question")
    }) | prompt | llm

    return chain

# Set book path
BOOK_PATH = "books/CISA Official Review Manual, 28th Edition[1].pdf"  # ‚úÖ Replace with your file
qa = load_book_qa(BOOK_PATH)

# Text-to-speech
def speak_text(text):
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

# Chat memory
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# UI
question = st.text_input("üí¨ Ask me anything about the book:")
speak = st.checkbox("üîä Speak the answer")

if question:
    with st.spinner("üí° Thinking..."):
        response = qa.invoke({"question": question})
        st.session_state.chat_history.append((question, response.content))
        st.markdown(f"**Answer:** {response.content}")
        if speak:
            speak_text(response.content)

# Show history
if st.session_state.chat_history:
    st.markdown("---")
    st.markdown("### üß† Chat History")
    for i, (q, a) in enumerate(st.session_state.chat_history[::-1], 1):
        st.markdown(f"**Q{i}:** {q}")
        st.markdown(f"**A{i}:** {a}")
